{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d74bca42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e076440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir=\"C:\\\\Users\\\\HP\\\\Documents\\\\PlantVillage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bbff6cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=(256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d75a46ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "642e07b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image_to_array(image_dir):\n",
    "    try:\n",
    "        image = cv2.imread(image_dir)\n",
    "        if image is not None:\n",
    "            image = cv2.resize(image, image_size)\n",
    "            return img_to_array(image)\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e4e130e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images...\n",
      "Image loading completed.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Set the path to your dataset directory\n",
    "dataset_dir = \"C:/Users/HP/Documents/PlantVillage\"\n",
    "\n",
    "# Define the image size\n",
    "image_size = (256, 256)\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Function to convert image to array\n",
    "def convert_image_to_array(image_dir):\n",
    "    try:\n",
    "        image = cv2.imread(image_dir)\n",
    "        if image is not None:\n",
    "            image = cv2.resize(image, image_size)\n",
    "            return img_to_array(image)\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load the images and labels\n",
    "image_list = []\n",
    "label_list = []\n",
    "\n",
    "print(\"Loading images...\")\n",
    "for root_folder in os.listdir(dataset_dir):\n",
    "    if root_folder != \".DS_Store\":\n",
    "        root_folder_path = os.path.join(dataset_dir, root_folder)\n",
    "        for plant_folder in os.listdir(root_folder_path):\n",
    "            if plant_folder != \".DS_Store\":\n",
    "                plant_folder_path = os.path.join(root_folder_path, plant_folder)\n",
    "                if os.path.isdir(plant_folder_path):  # Check if it's a directory\n",
    "                    for image_file in os.listdir(plant_folder_path)[:200]:\n",
    "                        if image_file.endswith(\".jpg\") or image_file.endswith(\".JPG\"):\n",
    "                            image_path = os.path.join(plant_folder_path, image_file)\n",
    "                            image_list.append(convert_image_to_array(image_path))\n",
    "                            label_list.append(plant_folder)\n",
    "\n",
    "print(\"Image loading completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9928c19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the image list and label list to numpy arrays\n",
    "X = np.array(image_list, dtype=np.float16) / 255.0\n",
    "y = np.array(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9beb9096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Specify the dataset directory containing the image data\n",
    "dataset_dir = \"C:/Users/HP/Documents/PlantVillage\"\n",
    "\n",
    "# Initialize lists to store image data and labels\n",
    "image_list = []\n",
    "label_list = []\n",
    "\n",
    "# Iterate over the dataset directory and load images\n",
    "for plant_folder in os.listdir(dataset_dir):\n",
    "    if plant_folder != \".DS_Store\":\n",
    "        plant_folder_path = os.path.join(dataset_dir, plant_folder)\n",
    "        for image_file in os.listdir(plant_folder_path)[:200]:\n",
    "            if image_file.endswith(\".jpg\") or image_file.endswith(\".JPG\"):\n",
    "                image_path = os.path.join(plant_folder_path, image_file)\n",
    "                try:\n",
    "                    image = cv2.imread(image_path)\n",
    "                    if image is not None:\n",
    "                        # Preprocess the image (resize, normalize, etc.)\n",
    "                        image = cv2.resize(image, (256, 256))  # Resize the image to 256x256\n",
    "                        image = image.astype('float32') / 255.0  # Normalize the pixel values to [0, 1]\n",
    "\n",
    "                        # Add the preprocessed image and label to the lists\n",
    "                        image_list.append(image)\n",
    "                        label_list.append(plant_folder)\n",
    "                    else:\n",
    "                        print(f\"Unable to read image: {image_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing image: {image_path} - {e}\")\n",
    "\n",
    "# Perform label binarization\n",
    "label_binarizer = LabelBinarizer()\n",
    "y = label_binarizer.fit_transform(label_list)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(image_list, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Rest of the code for model training and evaluation\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ff71e39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "54/54 [==============================] - 334s 6s/step - loss: 2.4486 - accuracy: 0.1209 - val_loss: 2.3230 - val_accuracy: 0.2135\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 307s 6s/step - loss: 2.2925 - accuracy: 0.1761 - val_loss: 2.2233 - val_accuracy: 0.1787\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 307s 6s/step - loss: 2.2146 - accuracy: 0.2162 - val_loss: 2.1605 - val_accuracy: 0.1879\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 309s 6s/step - loss: 2.1113 - accuracy: 0.2452 - val_loss: 2.1083 - val_accuracy: 0.2529\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 322s 6s/step - loss: 2.0534 - accuracy: 0.2870 - val_loss: 1.9558 - val_accuracy: 0.3828\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 340s 6s/step - loss: 1.9767 - accuracy: 0.3382 - val_loss: 1.9335 - val_accuracy: 0.3411\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 319s 6s/step - loss: 1.9153 - accuracy: 0.3597 - val_loss: 1.8457 - val_accuracy: 0.3735\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 394s 7s/step - loss: 1.8801 - accuracy: 0.3521 - val_loss: 1.8085 - val_accuracy: 0.4084\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 330s 6s/step - loss: 1.8045 - accuracy: 0.3742 - val_loss: 1.7573 - val_accuracy: 0.4084\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 314s 6s/step - loss: 1.7586 - accuracy: 0.4067 - val_loss: 1.6780 - val_accuracy: 0.4942\n",
      "14/14 [==============================] - 61s 4s/step - loss: 1.6780 - accuracy: 0.4942\n",
      "Test Accuracy: 0.4941995441913605\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Convert the image lists to NumPy arrays\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Load the pre-trained ResNet50 model (without the top classification layer)\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "# Add custom classification layers on top of the pre-trained base model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(len(label_binarizer.classes_), activation='softmax')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the weights of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "_, accuracy = model.evaluate(x_test, y_test)\n",
    "print('Test Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6308b0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "Predicted Labels:\n",
      "Apple__rust\n",
      "Apple__rust\n",
      "Apple__rust\n",
      "Apple__rust\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on new images\n",
    "new_images = np.array(image_list[1:5])  # Use the first 10 images for demonstration\n",
    "new_images = np.reshape(new_images, (-1, 256, 256, 3))\n",
    "new_images = new_images.astype('float32') / 255.0  # Normalize the pixel values to [0, 1]\n",
    "\n",
    "# Perform predictions\n",
    "predictions = model.predict(new_images)\n",
    "\n",
    "# Decode the predictions\n",
    "predicted_labels = label_binarizer.inverse_transform(predictions)\n",
    "print(\"Predicted Labels:\")\n",
    "for label in predicted_labels:\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be7bc60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_labels = {\n",
    "    \"Tomato__Target_Spot\": 0,\n",
    "    \"Tomato__Tomato_mosaic_virus\": 1,\n",
    "    \"Tomato__Tomato_YellowLeaf__Curl_Virus\": 2,\n",
    "    # Add more disease classes here\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0c1eb9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list.append(disease_labels\n",
    "                  [plant_folder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "de50f0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"C:/Users/HP/Documents/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f38b18e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Predicted Labels: ['Tomato__Tomato_mosaic_virus']\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model = load_model(\"C:/Users/HP/Documents/model.h5\")\n",
    "\n",
    "# Preprocess the new image\n",
    "new_image_path = \"C:/Users/HP/Documents/PlantVillage/Tomato__Tomato_mosaic_virus/0a7cc59f-b2b0-4201-9c4a-d91eca5c03a3___PSU_CG 2230.jpg\"\n",
    "new_image = cv2.imread(new_image_path)\n",
    "new_image = cv2.resize(new_image, (256, 256))\n",
    "new_image = new_image.astype('float32') / 255.0\n",
    "new_image = np.expand_dims(new_image, axis=0)  # Add an extra dimension for batch size\n",
    "\n",
    "# Perform prediction\n",
    "predictions = model.predict(new_image)\n",
    "\n",
    "# Decode the predictions\n",
    "predicted_labels = label_binarizer.inverse_transform(predictions)\n",
    "\n",
    "print(\"Predicted Labels:\", predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a3a65c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model(\"C:/Users/HP/Documents/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1a58cae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image = cv2.imread(new_image_path)\n",
    "if new_image is None:\n",
    "    print(f\"Unable to read image: {new_image_path}\")\n",
    "else:\n",
    "    new_image = cv2.resize(new_image, (256, 256))\n",
    "    new_image = new_image.astype('float32') / 255.0\n",
    "    new_image = np.expand_dims(new_image, axis=0)  # Add an extra dimension for batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "250a339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Load image using Pillow (alternative to cv2.imread)\n",
    "try:\n",
    "    image = Image.open(new_image_path)\n",
    "    # Perform resizing and preprocessing as needed\n",
    "    # ...\n",
    "except Exception as e:\n",
    "    print(f\"Unable to read image: {new_image_path} - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "72603cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Predicted Disease: Tomato__Tomato_mosaic_virus\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image_path = \"C:/Users/HP/Documents/PlantVillage/Tomato__Tomato_mosaic_virus/0a7cc59f-b2b0-4201-9c4a-d91eca5c03a3___PSU_CG 2230.jpg\"\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Check if the image was successfully loaded\n",
    "if image is not None:\n",
    "    # Preprocess the image\n",
    "    image = cv2.resize(image, (256, 256))\n",
    "    image = image.astype('float32') / 255.0\n",
    "    image = np.expand_dims(image, axis=0)  # Add an extra dimension for batch size\n",
    "\n",
    "    # Make predictions using the model\n",
    "    predictions = model.predict(image)\n",
    "\n",
    "    # Decode the predictions\n",
    "    predicted_labels = label_binarizer.inverse_transform(predictions)\n",
    "\n",
    "    # Print the predicted labels\n",
    "    print(\"Predicted Disease:\", predicted_labels[0])\n",
    "else:\n",
    "    print(\"Unable to read the image:\", image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "df9cd9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 249ms/step\n",
      "Predicted Disease: Tomato__Tomato_mosaic_virus\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Load the image\n",
    "image_path = \"C:/Users/HP/Documents/PlantVillage/Tomato__Tomato_mosaic_virus/0a7cc59f-b2b0-4201-9c4a-d91eca5c03a3___PSU_CG 2230.jpg\"\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Convert the image to RGB if it's in a different mode\n",
    "if image.mode != \"RGB\":\n",
    "    image = image.convert(\"RGB\")\n",
    "\n",
    "# Resize the image\n",
    "image = image.resize((256, 256))\n",
    "\n",
    "# Convert the image to a NumPy array\n",
    "image = np.array(image)\n",
    "\n",
    "# Preprocess the image\n",
    "image = image.astype('float32') / 255.0\n",
    "image = np.expand_dims(image, axis=0)  # Add an extra dimension for batch size\n",
    "\n",
    "# Make predictions using the model\n",
    "predictions = model.predict(image)\n",
    "\n",
    "# Decode the predictions\n",
    "predicted_labels = label_binarizer.inverse_transform(predictions)\n",
    "\n",
    "# Print the predicted labels\n",
    "print(\"Predicted Disease:\", predicted_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "99081e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 281ms/step\n",
      "Predicted label: Tomato__Tomato_mosaic_virus\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Specify the path to the image file\n",
    "image_path = \"C:/Users/HP/Documents/PlantVillage/Tomato__Tomato_mosaic_virus/0a91f50b-1263-4b2c-a8c1-f2a6025b82f3___PSU_CG 2136.jpg\"\n",
    "\n",
    "# Check if the image file exists\n",
    "if not os.path.isfile(image_path):\n",
    "    print(\"Image file not found!\")\n",
    "else:\n",
    "    try:\n",
    "        # Read the image\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Check if the image is loaded successfully\n",
    "        if image is None:\n",
    "            print(\"Failed to load image!\")\n",
    "        else:\n",
    "            # Preprocess the image\n",
    "            image = cv2.resize(image, (256, 256))\n",
    "            image = image.astype('float32') / 255.0\n",
    "            image = np.expand_dims(image, axis=0)  # Add an extra dimension for batch size\n",
    "\n",
    "            # Perform prediction using the loaded model\n",
    "            predictions = model.predict(image)\n",
    "\n",
    "            # Decode the predictions\n",
    "            predicted_labels = label_binarizer.inverse_transform(predictions)\n",
    "            print(\"Predicted label:\", predicted_labels[0])\n",
    "    except Exception as e:\n",
    "        print(\"Error processing image:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "68f05d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 258ms/step\n",
      "Predicted Labels: ['Tomato__Tomato_mosaic_virus']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define the image file path\n",
    "image_file = \"C:/Users/HP/Documents/PlantVillage/Tomato__Tomato_mosaic_virus/0a91f50b-1263-4b2c-a8c1-f2a6025b82f3___PSU_CG 2136.jpg\"\n",
    "\n",
    "# Check if the image file exists\n",
    "if not os.path.isfile(image_file):\n",
    "    print(f\"Image file not found: {image_file}\")\n",
    "    exit()\n",
    "\n",
    "# Load the image\n",
    "try:\n",
    "    image = cv2.imread(image_file)\n",
    "    if image is None:\n",
    "        print(f\"Unable to read image file: {image_file}\")\n",
    "        exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading image file: {image_file} - {e}\")\n",
    "    exit()\n",
    "\n",
    "# Preprocess the image\n",
    "try:\n",
    "    image = cv2.resize(image, (256, 256))\n",
    "    image = image.astype('float32') / 255.0\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "except Exception as e:\n",
    "    print(f\"Error preprocessing image: {image_file} - {e}\")\n",
    "    exit()\n",
    "\n",
    "# Perform prediction using the loaded model\n",
    "try:\n",
    "    predictions = model.predict(image)\n",
    "    predicted_labels = label_binarizer.inverse_transform(predictions)\n",
    "    print(\"Predicted Labels:\", predicted_labels)\n",
    "except Exception as e:\n",
    "    print(f\"Error performing prediction: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "91e37b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = load_model(\"C:/Users/HP/Documents/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48edad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Specify the dataset directory containing the image data\n",
    "dataset_dir = \"C:/Users/HP/Documents/PlantVillage\"\n",
    "\n",
    "# Initialize lists to store image data and labels\n",
    "image_list = []\n",
    "label_list = []\n",
    "\n",
    "# Iterate over the dataset directory and load images\n",
    "for plant_folder in os.listdir(dataset_dir):\n",
    "    if plant_folder != \".DS_Store\":\n",
    "        plant_folder_path = os.path.join(dataset_dir, plant_folder)\n",
    "        for image_file in os.listdir(plant_folder_path)[:200]:\n",
    "            if image_file.endswith(\".jpg\") or image_file.endswith(\".JPG\"):\n",
    "                image_path = os.path.join(plant_folder_path, image_file)\n",
    "                try:\n",
    "                    image = cv2.imread(image_path)\n",
    "                    if image is not None:\n",
    "                        # Preprocess the image (resize, normalize, etc.)\n",
    "                        image = cv2.resize(image, (299, 299))  # Resize the image to 299x299 for InceptionV3\n",
    "                        image = image.astype('float32') / 255.0  # Normalize the pixel values to [0, 1]\n",
    "\n",
    "                        # Add the preprocessed image and label to the lists\n",
    "                        image_list.append(image)\n",
    "                        label_list.append(plant_folder)\n",
    "                    else:\n",
    "                        print(f\"Unable to read image: {image_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing image: {image_path} - {e}\")\n",
    "\n",
    "# Perform label binarization\n",
    "label_binarizer = LabelBinarizer()\n",
    "y = label_binarizer.fit_transform(label_list)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(image_list, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the image lists to NumPy arrays\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Load the pre-trained InceptionV3 model (without the top classification layer)\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
    "\n",
    "# Add custom classification layers on top of the pre-trained base model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(len(label_binarizer.classes_), activation='softmax')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the weights of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5, batch_size=32)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "_, accuracy = model.evaluate(x_test, y_test)\n",
    "print('Test Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "36e3b01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "01f628da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the dataset directory containing the image data\n",
    "dataset_dir = \"C:/Users/HP/Documents/PlantVillage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7fc19b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store image data and labels\n",
    "image_list = []\n",
    "label_list = []\n",
    "\n",
    "# Iterate over the dataset directory and load images\n",
    "for plant_folder in os.listdir(dataset_dir):\n",
    "    if plant_folder != \".DS_Store\":\n",
    "        plant_folder_path = os.path.join(dataset_dir, plant_folder)\n",
    "        for image_file in os.listdir(plant_folder_path)[:200]:\n",
    "            if image_file.endswith(\".jpg\") or image_file.endswith(\".JPG\"):\n",
    "                image_path = os.path.join(plant_folder_path, image_file)\n",
    "                try:\n",
    "                    image = cv2.imread(image_path)\n",
    "                    if image is not None:\n",
    "                        # Preprocess the image (resize, normalize, etc.)\n",
    "                        image = cv2.resize(image, (299, 299))  # Resize the image to 299x299 for InceptionV3\n",
    "                        image = image.astype('float32') / 255.0  # Normalize the pixel values to [0, 1]\n",
    "\n",
    "                        # Add the preprocessed image and label to the lists\n",
    "                        image_list.append(image)\n",
    "                        label_list.append(plant_folder)\n",
    "                    else:\n",
    "                        print(f\"Unable to read image: {image_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing image: {image_path} - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b5318524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform label binarization\n",
    "label_binarizer = LabelBinarizer()\n",
    "y = label_binarizer.fit_transform(label_list)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(image_list, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the image lists to NumPy arrays\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e95f41ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained InceptionV3 model (without the top classification layer)\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
    "\n",
    "# Add custom classification layers on top of the pre-trained base model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(len(label_binarizer.classes_), activation='softmax')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe21f29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "54/54 [==============================] - 381s 7s/step - loss: 0.1607 - accuracy: 0.9541 - val_loss: 0.1728 - val_accuracy: 0.9350\n",
      "Epoch 2/5\n",
      "54/54 [==============================] - 418s 8s/step - loss: 0.0943 - accuracy: 0.9826 - val_loss: 0.1785 - val_accuracy: 0.9327\n",
      "Epoch 3/5\n",
      "54/54 [==============================] - 380s 7s/step - loss: 0.0612 - accuracy: 0.9959 - val_loss: 0.1680 - val_accuracy: 0.9188\n",
      "Epoch 4/5\n",
      "54/54 [==============================] - 362s 7s/step - loss: 0.0460 - accuracy: 0.9965 - val_loss: 0.1320 - val_accuracy: 0.9490\n",
      "Epoch 5/5\n",
      "54/54 [==============================] - 364s 7s/step - loss: 0.0431 - accuracy: 0.9971 - val_loss: 0.1836 - val_accuracy: 0.9397\n",
      "14/14 [==============================] - 73s 5s/step - loss: 0.1836 - accuracy: 0.9397\n",
      "Test Accuracy: 0.9396751523017883\n"
     ]
    }
   ],
   "source": [
    "# Freeze the weights of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5, batch_size=32)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "_, accuracy = model.evaluate(x_test, y_test)\n",
    "print('Test Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f06feca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 299, 299, 3)\n"
     ]
    }
   ],
   "source": [
    "print(new_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b45cb21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 829ms/step\n",
      "Predicted Labels:\n",
      "Apple__rust\n",
      "Apple__rust\n",
      "Apple__rust\n",
      "Apple__rust\n",
      "Apple__rust\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on new images\n",
    "new_images = np.array(image_list[:5])  # Use the first 4 images for demonstration\n",
    "new_images_resized = np.array([cv2.resize(image, (256, 256)) for image in new_images])\n",
    "new_images_resized = new_images_resized.astype('float32') / 255.0  # Normalize the pixel values to [0, 1]\n",
    "\n",
    "# Perform predictions\n",
    "predictions = model.predict(new_images_resized)\n",
    "\n",
    "# Decode the predictions\n",
    "predicted_labels = label_binarizer.inverse_transform(predictions)\n",
    "print(\"Predicted Labels:\")\n",
    "for label in predicted_labels:\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a8ce7070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 258ms/step\n",
      "Predicted Labels:\n",
      "Potato___healthy\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define the image paths\n",
    "image_paths = [\n",
    "    \"C:/Users/HP/Documents/PlantVillage/Potato___healthy/0f4ebc5a-d646-436a-919d-961342997cde___RS_HL 4183.jpg\"]\n",
    "\n",
    "# Load and preprocess the images\n",
    "new_images = []\n",
    "for image_path in image_paths:\n",
    "    try:\n",
    "        # Read the image\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is not None:\n",
    "            # Resize the image to (256, 256)\n",
    "            image = cv2.resize(image, (256, 256))\n",
    "            image = image.astype('float32') / 255.0  # Normalize the pixel values to [0, 1]\n",
    "            new_images.append(image)\n",
    "        else:\n",
    "            print(f\"Unable to read image: {image_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {image_path} - {e}\")\n",
    "\n",
    "# Convert the list of images to a NumPy array\n",
    "new_images = np.array(new_images)\n",
    "\n",
    "# Perform predictions\n",
    "predictions = model.predict(new_images)\n",
    "\n",
    "# Decode the predictions\n",
    "predicted_labels = label_binarizer.inverse_transform(predictions)\n",
    "print(\"Predicted Labels:\")\n",
    "for label in predicted_labels:\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c518859c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
